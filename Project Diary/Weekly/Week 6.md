# Monday
### Daily Scrum:
#### Accomplished yesterday:
- Moved and formatted the Research Questions to Obsidian Vault.
#### To accomplish today:
- Make sure the observations from last week have all the metrics required.
- Change the reward system and test in both environments.
- Check if recent disabling of wind and motion features improved the realistic environment computational time and try to optimise if not.
- Make observations.
- Explore with automation script to automate the production of plot images and data capturing.

#### Obstacles met:
- Training time in the "realistic" environment is quite long and visible observations are almost impossible.

# Tuesday
### Daily Scrum:
#### Accomplished yesterday:
- Changed the activate_env.bat script to also activate tensorboard automatically.
- Changed the reward system for hunter agents - reward for spotting the prey agent.
- Partially set up the project on my laptop.
#### To accomplish today:
- Experiment more with the reward system and test it.
- Check the performance of the realistic environment.
- Make observations.
#### Obstacles met:
- Further automation of run script can be time consuming. 

# Wednesday
### Daily Scrum:
#### Accomplished yesterday:
- Cleaned up the code a bit and fixed few issues.
- Run the training in the simple environment and taken observation.
- Begun with documenting my observation.
#### To accomplish today:
- Complete documenting the observation.
- Consider more plots / observation to be documented in the observations section.
- Run the training in the realistic environment if successful.
## Obstacles met:
- Little change ("Curiosity") in agents' behaviour, cannot progress with achieving any form of strategy in their behaviour.
- There may be more to training parameters than I initially though, need to have a further reading at some point but may end up being a waste of precious time - just a week until mid project demo.

# Thursday
### Daily Scrum:
#### Accomplished yesterday:
- Trained another model with changed rewards.
- Documented my observations for two trained models.
- Included "Loss Value" plot for my observations.
#### To accomplish today:
- Run a training with more *aggressive* reward system
- create a mid-project demo presentation.
## Obstacles met:
- Control over ray angle seems to be too complicated for the agents.
- Training may need to be longer to achieve good results.