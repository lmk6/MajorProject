{
    "name": "root",
    "gauges": {
        "HunterController.Policy.Entropy.mean": {
            "value": 1.3341712951660156,
            "min": 1.3341712951660156,
            "max": 1.4170092344284058,
            "count": 15
        },
        "HunterController.Policy.Entropy.sum": {
            "value": 66886.0078125,
            "min": 66436.484375,
            "max": 74081.2421875,
            "count": 15
        },
        "HunterController.Step.mean": {
            "value": 749941.0,
            "min": 49968.0,
            "max": 749941.0,
            "count": 15
        },
        "HunterController.Step.sum": {
            "value": 749941.0,
            "min": 49968.0,
            "max": 749941.0,
            "count": 15
        },
        "HunterController.Policy.ExtrinsicValueEstimate.mean": {
            "value": 42.160606384277344,
            "min": -4.592324733734131,
            "max": 42.160606384277344,
            "count": 15
        },
        "HunterController.Policy.ExtrinsicValueEstimate.sum": {
            "value": 35625.7109375,
            "min": -3866.7373046875,
            "max": 35625.7109375,
            "count": 15
        },
        "HunterController.Environment.EpisodeLength.mean": {
            "value": 270.1703296703297,
            "min": 260.1855670103093,
            "max": 281.4082840236686,
            "count": 15
        },
        "HunterController.Environment.EpisodeLength.sum": {
            "value": 49171.0,
            "min": 45579.0,
            "max": 52027.0,
            "count": 15
        },
        "HunterController.Environment.CumulativeReward.mean": {
            "value": 200.04511214565971,
            "min": -13.872120759342655,
            "max": 200.04511214565971,
            "count": 15
        },
        "HunterController.Environment.CumulativeReward.sum": {
            "value": 36808.30063480139,
            "min": -2288.8999252915382,
            "max": 37394.20078355074,
            "count": 15
        },
        "HunterController.Policy.ExtrinsicReward.mean": {
            "value": 200.04511214565971,
            "min": -13.872120759342655,
            "max": 200.04511214565971,
            "count": 15
        },
        "HunterController.Policy.ExtrinsicReward.sum": {
            "value": 36808.30063480139,
            "min": -2288.8999252915382,
            "max": 37394.20078355074,
            "count": 15
        },
        "HunterController.Losses.PolicyLoss.mean": {
            "value": 0.026228248689052026,
            "min": 0.020291715256219808,
            "max": 0.026228248689052026,
            "count": 15
        },
        "HunterController.Losses.PolicyLoss.sum": {
            "value": 0.13114124344526013,
            "min": 0.08116686102487923,
            "max": 0.13114124344526013,
            "count": 15
        },
        "HunterController.Losses.ValueLoss.mean": {
            "value": 338.2402408854167,
            "min": 30.5372431564331,
            "max": 399.70060913085933,
            "count": 15
        },
        "HunterController.Losses.ValueLoss.sum": {
            "value": 1691.2012044270834,
            "min": 152.6862157821655,
            "max": 1998.5030456542968,
            "count": 15
        },
        "HunterController.Policy.LearningRate.mean": {
            "value": 9.866416711226672e-06,
            "min": 9.866416711226672e-06,
            "max": 0.00028921740359420003,
            "count": 15
        },
        "HunterController.Policy.LearningRate.sum": {
            "value": 4.933208355613336e-05,
            "min": 4.933208355613336e-05,
            "max": 0.0013487456504181331,
            "count": 15
        },
        "HunterController.Policy.Epsilon.mean": {
            "value": 0.10328877333333333,
            "min": 0.10328877333333333,
            "max": 0.19640580000000005,
            "count": 15
        },
        "HunterController.Policy.Epsilon.sum": {
            "value": 0.5164438666666666,
            "min": 0.5164438666666666,
            "max": 0.9495818666666668,
            "count": 15
        },
        "HunterController.Policy.Beta.mean": {
            "value": 0.00017410978933333338,
            "min": 0.00017410978933333338,
            "max": 0.004820649420000001,
            "count": 15
        },
        "HunterController.Policy.Beta.sum": {
            "value": 0.0008705489466666669,
            "min": 0.0008705489466666669,
            "max": 0.022484135146666664,
            "count": 15
        },
        "HunterController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 15
        },
        "HunterController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 15
        },
        "PreyController.Policy.Entropy.mean": {
            "value": 1.4159096479415894,
            "min": 1.4147827625274658,
            "max": 1.4255791902542114,
            "count": 15
        },
        "PreyController.Policy.Entropy.sum": {
            "value": 70911.5859375,
            "min": 70232.5859375,
            "max": 74244.34375,
            "count": 15
        },
        "PreyController.Step.mean": {
            "value": 749941.0,
            "min": 49968.0,
            "max": 749941.0,
            "count": 15
        },
        "PreyController.Step.sum": {
            "value": 749941.0,
            "min": 49968.0,
            "max": 749941.0,
            "count": 15
        },
        "PreyController.Policy.ExtrinsicValueEstimate.mean": {
            "value": 9.02546501159668,
            "min": 2.1762235164642334,
            "max": 11.060328483581543,
            "count": 15
        },
        "PreyController.Policy.ExtrinsicValueEstimate.sum": {
            "value": 7626.517578125,
            "min": 1821.4990234375,
            "max": 9390.21875,
            "count": 15
        },
        "PreyController.Environment.EpisodeLength.mean": {
            "value": 270.1703296703297,
            "min": 260.1855670103093,
            "max": 281.4082840236686,
            "count": 15
        },
        "PreyController.Environment.EpisodeLength.sum": {
            "value": 49171.0,
            "min": 45579.0,
            "max": 52584.0,
            "count": 15
        },
        "PreyController.Environment.CumulativeReward.mean": {
            "value": 26.358695652173914,
            "min": 19.623655913978496,
            "max": 36.29032258064516,
            "count": 15
        },
        "PreyController.Environment.CumulativeReward.sum": {
            "value": 4850.0,
            "min": 3650.0,
            "max": 6750.0,
            "count": 15
        },
        "PreyController.Policy.ExtrinsicReward.mean": {
            "value": 26.358695652173914,
            "min": 19.623655913978496,
            "max": 36.29032258064516,
            "count": 15
        },
        "PreyController.Policy.ExtrinsicReward.sum": {
            "value": 4850.0,
            "min": 3650.0,
            "max": 6750.0,
            "count": 15
        },
        "PreyController.Losses.PolicyLoss.mean": {
            "value": 0.023924101697436223,
            "min": 0.022052898344748727,
            "max": 0.026229097169319475,
            "count": 15
        },
        "PreyController.Losses.PolicyLoss.sum": {
            "value": 0.11962050848718112,
            "min": 0.09117244187315615,
            "max": 0.12635991903177152,
            "count": 15
        },
        "PreyController.Losses.ValueLoss.mean": {
            "value": 72.6649882253011,
            "min": 57.320515950520836,
            "max": 91.57244435628255,
            "count": 15
        },
        "PreyController.Losses.ValueLoss.sum": {
            "value": 363.3249411265055,
            "min": 229.28206380208334,
            "max": 457.8622217814127,
            "count": 15
        },
        "PreyController.Policy.LearningRate.mean": {
            "value": 9.866416711226672e-06,
            "min": 9.866416711226672e-06,
            "max": 0.00028921740359420003,
            "count": 15
        },
        "PreyController.Policy.LearningRate.sum": {
            "value": 4.933208355613336e-05,
            "min": 4.933208355613336e-05,
            "max": 0.0013487456504181331,
            "count": 15
        },
        "PreyController.Policy.Epsilon.mean": {
            "value": 0.10328877333333333,
            "min": 0.10328877333333333,
            "max": 0.19640580000000005,
            "count": 15
        },
        "PreyController.Policy.Epsilon.sum": {
            "value": 0.5164438666666666,
            "min": 0.5164438666666666,
            "max": 0.9495818666666668,
            "count": 15
        },
        "PreyController.Policy.Beta.mean": {
            "value": 0.00017410978933333338,
            "min": 0.00017410978933333338,
            "max": 0.004820649420000001,
            "count": 15
        },
        "PreyController.Policy.Beta.sum": {
            "value": 0.0008705489466666669,
            "min": 0.0008705489466666669,
            "max": 0.022484135146666664,
            "count": 15
        },
        "PreyController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 15
        },
        "PreyController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 15
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1710702221",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Lukas\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn C:\\MajorProject\\MP_ML_agents\\Assets\\TrainConfigMAgents.yaml --run-id=PreyVsHunter_19",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.0+cpu",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1710703011"
    },
    "total": 789.9053540000023,
    "count": 1,
    "self": 0.010905400005867705,
    "children": {
        "run_training.setup": {
            "total": 0.06176769999729004,
            "count": 1,
            "self": 0.06176769999729004
        },
        "TrainerController.start_learning": {
            "total": 789.8326808999991,
            "count": 1,
            "self": 0.26430010063631926,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.215386800002307,
                    "count": 1,
                    "self": 6.215386800002307
                },
                "TrainerController.advance": {
                    "total": 783.2571983993548,
                    "count": 16539,
                    "self": 0.1207947993389098,
                    "children": {
                        "env_step": {
                            "total": 783.1364036000159,
                            "count": 16539,
                            "self": 664.9468743991747,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 118.0614977994992,
                                    "count": 16539,
                                    "self": 1.6347743986261776,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 116.42672340087302,
                                            "count": 30090,
                                            "self": 116.42672340087302
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.12803140134201385,
                                    "count": 16539,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 784.1160044000862,
                                            "count": 16539,
                                            "is_parallel": true,
                                            "self": 258.8664062002499,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0049617999902693555,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00012069997319485992,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0048411000170744956,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0048411000170744956
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 525.2446363998461,
                                                    "count": 16539,
                                                    "is_parallel": true,
                                                    "self": 8.695993798290147,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 11.925315600485192,
                                                            "count": 16539,
                                                            "is_parallel": true,
                                                            "self": 11.925315600485192
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 483.09220869938144,
                                                            "count": 16539,
                                                            "is_parallel": true,
                                                            "self": 483.09220869938144
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 21.531118301689276,
                                                            "count": 33078,
                                                            "is_parallel": true,
                                                            "self": 2.78210320098151,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 18.749015100707766,
                                                                    "count": 132312,
                                                                    "is_parallel": true,
                                                                    "self": 18.749015100707766
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.1800009310245514e-05,
                    "count": 1,
                    "self": 3.1800009310245514e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 1566.5154642018024,
                                    "count": 70873,
                                    "is_parallel": true,
                                    "self": 1.6571225016377866,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 1108.3836109003023,
                                            "count": 70873,
                                            "is_parallel": true,
                                            "self": 1108.1135863003146,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.27002459998766426,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.27002459998766426
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 456.4747307998623,
                                            "count": 144,
                                            "is_parallel": true,
                                            "self": 151.98062009984278,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 304.4941107000195,
                                                    "count": 4326,
                                                    "is_parallel": true,
                                                    "self": 304.4941107000195
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.0957637999963481,
                    "count": 1,
                    "self": 0.02864509998471476,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06711870001163334,
                            "count": 2,
                            "self": 0.06711870001163334
                        }
                    }
                }
            }
        }
    }
}