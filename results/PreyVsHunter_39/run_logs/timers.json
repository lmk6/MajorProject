{
    "name": "root",
    "gauges": {
        "PreyController.Policy.Entropy.mean": {
            "value": 1.4068151712417603,
            "min": 1.4068151712417603,
            "max": 1.4257556200027466,
            "count": 40
        },
        "PreyController.Policy.Entropy.sum": {
            "value": 70527.8671875,
            "min": 65385.2734375,
            "max": 86929.90625,
            "count": 40
        },
        "PreyController.Environment.EpisodeLength.mean": {
            "value": 88.87096774193549,
            "min": 84.793867120954,
            "max": 289.72189349112426,
            "count": 40
        },
        "PreyController.Environment.EpisodeLength.sum": {
            "value": 49590.0,
            "min": 46052.0,
            "max": 55655.0,
            "count": 40
        },
        "PreyController.Step.mean": {
            "value": 1999918.0,
            "min": 49849.0,
            "max": 1999918.0,
            "count": 40
        },
        "PreyController.Step.sum": {
            "value": 1999918.0,
            "min": 49849.0,
            "max": 1999918.0,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicValueEstimate.mean": {
            "value": -25.08793830871582,
            "min": -25.200008392333984,
            "max": 10.302371978759766,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicValueEstimate.sum": {
            "value": -13973.9814453125,
            "min": -14601.361328125,
            "max": 1916.2412109375,
            "count": 40
        },
        "PreyController.Environment.CumulativeReward.mean": {
            "value": -45.960502692998205,
            "min": -46.33105802047782,
            "max": 43.67816091954023,
            "count": 40
        },
        "PreyController.Environment.CumulativeReward.sum": {
            "value": -25600.0,
            "min": -27150.0,
            "max": 7600.0,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicReward.mean": {
            "value": -45.960502692998205,
            "min": -46.33105802047782,
            "max": 43.67816091954023,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicReward.sum": {
            "value": -25600.0,
            "min": -27150.0,
            "max": 7600.0,
            "count": 40
        },
        "PreyController.Losses.PolicyLoss.mean": {
            "value": 0.01655514449632998,
            "min": 0.014005546259795665,
            "max": 0.018760439373872943,
            "count": 40
        },
        "PreyController.Losses.PolicyLoss.sum": {
            "value": 0.04966543348898994,
            "min": 0.02801109251959133,
            "max": 0.056226237431401385,
            "count": 40
        },
        "PreyController.Losses.ValueLoss.mean": {
            "value": 102.46873123168945,
            "min": 52.36042893149636,
            "max": 130.80779907226562,
            "count": 40
        },
        "PreyController.Losses.ValueLoss.sum": {
            "value": 307.40619369506834,
            "min": 104.72085786299272,
            "max": 390.5008752441406,
            "count": 40
        },
        "PreyController.Policy.LearningRate.mean": {
            "value": 1.1503988497000005e-06,
            "min": 1.1503988497000005e-06,
            "max": 9.824415175585001e-05,
            "count": 40
        },
        "PreyController.Policy.LearningRate.sum": {
            "value": 3.4511965491000017e-06,
            "min": 3.4511965491000017e-06,
            "max": 0.0002736596263404,
            "count": 40
        },
        "PreyController.Policy.Epsilon.mean": {
            "value": 0.10115029999999998,
            "min": 0.10115029999999998,
            "max": 0.19824415,
            "count": 40
        },
        "PreyController.Policy.Epsilon.sum": {
            "value": 0.30345089999999997,
            "min": 0.20743679999999998,
            "max": 0.5736596,
            "count": 40
        },
        "PreyController.Policy.Beta.mean": {
            "value": 6.739997000000004e-05,
            "min": 6.739997000000004e-05,
            "max": 0.004912383084999999,
            "count": 40
        },
        "PreyController.Policy.Beta.sum": {
            "value": 0.0002021999100000001,
            "min": 0.0002021999100000001,
            "max": 0.013685614039999999,
            "count": 40
        },
        "PreyController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "PreyController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "HunterController.Policy.Entropy.mean": {
            "value": 1.4052417278289795,
            "min": 1.4052417278289795,
            "max": 1.4226986169815063,
            "count": 40
        },
        "HunterController.Policy.Entropy.sum": {
            "value": 70448.984375,
            "min": 65451.546875,
            "max": 86950.0546875,
            "count": 40
        },
        "HunterController.Environment.EpisodeLength.mean": {
            "value": 88.87096774193549,
            "min": 84.793867120954,
            "max": 289.72189349112426,
            "count": 40
        },
        "HunterController.Environment.EpisodeLength.sum": {
            "value": 49590.0,
            "min": 46052.0,
            "max": 55655.0,
            "count": 40
        },
        "HunterController.Step.mean": {
            "value": 1999918.0,
            "min": 49849.0,
            "max": 1999918.0,
            "count": 40
        },
        "HunterController.Step.sum": {
            "value": 1999918.0,
            "min": 49849.0,
            "max": 1999918.0,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicValueEstimate.mean": {
            "value": 23.974124908447266,
            "min": -17.856727600097656,
            "max": 24.254348754882812,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicValueEstimate.sum": {
            "value": 13353.587890625,
            "min": -3097.28125,
            "max": 14213.0478515625,
            "count": 40
        },
        "HunterController.Environment.CumulativeReward.mean": {
            "value": 50.18976673617611,
            "min": -62.11342783791678,
            "max": 50.18976673617611,
            "count": 40
        },
        "HunterController.Environment.CumulativeReward.sum": {
            "value": 27955.700072050095,
            "min": -10869.849871635437,
            "max": 29162.300163269043,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicReward.mean": {
            "value": 50.18976673617611,
            "min": -62.11342783791678,
            "max": 50.18976673617611,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicReward.sum": {
            "value": 27955.700072050095,
            "min": -10869.849871635437,
            "max": 29162.300163269043,
            "count": 40
        },
        "HunterController.Losses.PolicyLoss.mean": {
            "value": 0.01701489605101718,
            "min": 0.014599911025713178,
            "max": 0.02069189388595987,
            "count": 40
        },
        "HunterController.Losses.PolicyLoss.sum": {
            "value": 0.05104468815305154,
            "min": 0.029199822051426357,
            "max": 0.05695629293768434,
            "count": 40
        },
        "HunterController.Losses.ValueLoss.mean": {
            "value": 104.32060501098631,
            "min": 15.22322659925981,
            "max": 111.63470573425292,
            "count": 40
        },
        "HunterController.Losses.ValueLoss.sum": {
            "value": 312.96181503295895,
            "min": 30.44645319851962,
            "max": 328.18169326782225,
            "count": 40
        },
        "HunterController.Policy.LearningRate.mean": {
            "value": 1.1503988497000005e-06,
            "min": 1.1503988497000005e-06,
            "max": 9.824415175585001e-05,
            "count": 40
        },
        "HunterController.Policy.LearningRate.sum": {
            "value": 3.4511965491000017e-06,
            "min": 3.4511965491000017e-06,
            "max": 0.0002736596263404,
            "count": 40
        },
        "HunterController.Policy.Epsilon.mean": {
            "value": 0.10115029999999998,
            "min": 0.10115029999999998,
            "max": 0.19824415,
            "count": 40
        },
        "HunterController.Policy.Epsilon.sum": {
            "value": 0.30345089999999997,
            "min": 0.20743679999999998,
            "max": 0.5736596,
            "count": 40
        },
        "HunterController.Policy.Beta.mean": {
            "value": 6.739997000000004e-05,
            "min": 6.739997000000004e-05,
            "max": 0.004912383084999999,
            "count": 40
        },
        "HunterController.Policy.Beta.sum": {
            "value": 0.0002021999100000001,
            "min": 0.0002021999100000001,
            "max": 0.013685614039999999,
            "count": 40
        },
        "HunterController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "HunterController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1711295298",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Lukas\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn C:\\MajorProject\\MP_ML_agents\\Assets\\TrainConfigMAgents.yaml --run-id=PreyVsHunter_39",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.0+cpu",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1711298236"
    },
    "total": 2938.411570299999,
    "count": 1,
    "self": 0.008157399999618065,
    "children": {
        "run_training.setup": {
            "total": 0.05932599999869126,
            "count": 1,
            "self": 0.05932599999869126
        },
        "TrainerController.start_learning": {
            "total": 2938.3440869000005,
            "count": 1,
            "self": 0.7709809999141726,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.996835800000554,
                    "count": 1,
                    "self": 5.996835800000554
                },
                "TrainerController.advance": {
                    "total": 2931.4805186000885,
                    "count": 50042,
                    "self": 0.37643329929414904,
                    "children": {
                        "env_step": {
                            "total": 2931.1040853007944,
                            "count": 50042,
                            "self": 2424.2585898008656,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 506.44225450022714,
                                    "count": 50042,
                                    "self": 4.901112099294551,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 501.5411424009326,
                                            "count": 78604,
                                            "self": 501.5411424009326
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.4032409997016657,
                                    "count": 50042,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 2932.1585419004477,
                                            "count": 50042,
                                            "is_parallel": true,
                                            "self": 1037.9762852005624,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0023575999985041562,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00016589999358984642,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00219170000491431,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.00219170000491431
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1894.1798990998868,
                                                    "count": 50042,
                                                    "is_parallel": true,
                                                    "self": 31.73837080026351,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 36.16668329977256,
                                                            "count": 50042,
                                                            "is_parallel": true,
                                                            "self": 36.16668329977256
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1740.1570876999467,
                                                            "count": 50042,
                                                            "is_parallel": true,
                                                            "self": 1740.1570876999467
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 86.11775729990404,
                                                            "count": 100084,
                                                            "is_parallel": true,
                                                            "self": 8.821685800267005,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 77.29607149963704,
                                                                    "count": 400336,
                                                                    "is_parallel": true,
                                                                    "self": 77.29607149963704
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.989999822806567e-05,
                    "count": 1,
                    "self": 3.989999822806567e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 5862.753344299974,
                                    "count": 222687,
                                    "is_parallel": true,
                                    "self": 5.713002799169772,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 3616.7623478008245,
                                            "count": 222687,
                                            "is_parallel": true,
                                            "self": 3616.0047443008334,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.7576034999910917,
                                                    "count": 8,
                                                    "is_parallel": true,
                                                    "self": 0.7576034999910917
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 2240.2779936999796,
                                            "count": 192,
                                            "is_parallel": true,
                                            "self": 824.0209227997366,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 1416.257070900243,
                                                    "count": 9650,
                                                    "is_parallel": true,
                                                    "self": 1416.257070900243
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.09571159999904921,
                    "count": 1,
                    "self": 0.016606799996225163,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07910480000282405,
                            "count": 2,
                            "self": 0.07910480000282405
                        }
                    }
                }
            }
        }
    }
}