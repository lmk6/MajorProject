{
    "name": "root",
    "gauges": {
        "PreyController.Policy.Entropy.mean": {
            "value": 1.4293620586395264,
            "min": 1.4193611145019531,
            "max": 1.4330849647521973,
            "count": 40
        },
        "PreyController.Policy.Entropy.sum": {
            "value": 72168.4921875,
            "min": 66313.3359375,
            "max": 86937.2890625,
            "count": 40
        },
        "PreyController.Environment.EpisodeLength.mean": {
            "value": 287.09248554913296,
            "min": 287.09248554913296,
            "max": 584.8117647058823,
            "count": 40
        },
        "PreyController.Environment.EpisodeLength.sum": {
            "value": 49667.0,
            "min": 45138.0,
            "max": 54494.0,
            "count": 40
        },
        "PreyController.Step.mean": {
            "value": 1999866.0,
            "min": 49456.0,
            "max": 1999866.0,
            "count": 40
        },
        "PreyController.Step.sum": {
            "value": 1999866.0,
            "min": 49456.0,
            "max": 1999866.0,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicValueEstimate.mean": {
            "value": -7.894919395446777,
            "min": -7.894919395446777,
            "max": 5.984182357788086,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicValueEstimate.sum": {
            "value": -1365.821044921875,
            "min": -1365.821044921875,
            "max": 526.6080322265625,
            "count": 40
        },
        "PreyController.Environment.CumulativeReward.mean": {
            "value": -33.8150289017341,
            "min": -33.8150289017341,
            "max": 41.1764705882353,
            "count": 40
        },
        "PreyController.Environment.CumulativeReward.sum": {
            "value": -5850.0,
            "min": -5850.0,
            "max": 3550.0,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicReward.mean": {
            "value": -33.8150289017341,
            "min": -33.8150289017341,
            "max": 41.1764705882353,
            "count": 40
        },
        "PreyController.Policy.ExtrinsicReward.sum": {
            "value": -5850.0,
            "min": -5850.0,
            "max": 3550.0,
            "count": 40
        },
        "PreyController.Losses.PolicyLoss.mean": {
            "value": 0.015365998955276154,
            "min": 0.014222120406884642,
            "max": 0.0184898986373446,
            "count": 40
        },
        "PreyController.Losses.PolicyLoss.sum": {
            "value": 0.030731997910552308,
            "min": 0.014325279278609042,
            "max": 0.05425693191005848,
            "count": 40
        },
        "PreyController.Losses.ValueLoss.mean": {
            "value": 67.60645538330078,
            "min": 30.640065383911132,
            "max": 67.60645538330078,
            "count": 40
        },
        "PreyController.Losses.ValueLoss.sum": {
            "value": 135.21291076660157,
            "min": 61.60646426861103,
            "max": 194.85456764221192,
            "count": 40
        },
        "PreyController.Policy.LearningRate.mean": {
            "value": 1.5352234648749983e-06,
            "min": 1.5352234648749983e-06,
            "max": 9.864495135505001e-05,
            "count": 40
        },
        "PreyController.Policy.LearningRate.sum": {
            "value": 3.0704469297499966e-06,
            "min": 3.0704469297499966e-06,
            "max": 0.00028108566891435,
            "count": 40
        },
        "PreyController.Policy.Epsilon.mean": {
            "value": 0.101535125,
            "min": 0.101535125,
            "max": 0.19864495000000001,
            "count": 40
        },
        "PreyController.Policy.Epsilon.sum": {
            "value": 0.20307025,
            "min": 0.19864495000000001,
            "max": 0.5810856500000001,
            "count": 40
        },
        "PreyController.Policy.Beta.mean": {
            "value": 8.660273749999992e-05,
            "min": 8.660273749999992e-05,
            "max": 0.004932383005,
            "count": 40
        },
        "PreyController.Policy.Beta.sum": {
            "value": 0.00017320547499999984,
            "min": 0.00017320547499999984,
            "max": 0.014056173935,
            "count": 40
        },
        "PreyController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "PreyController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "HunterController.Policy.Entropy.mean": {
            "value": 1.4000364542007446,
            "min": 1.4000364542007446,
            "max": 1.4218496084213257,
            "count": 40
        },
        "HunterController.Policy.Entropy.sum": {
            "value": 66974.9453125,
            "min": 58011.1484375,
            "max": 87201.4609375,
            "count": 40
        },
        "HunterController.Environment.EpisodeLength.mean": {
            "value": 287.644578313253,
            "min": 287.644578313253,
            "max": 584.8117647058823,
            "count": 40
        },
        "HunterController.Environment.EpisodeLength.sum": {
            "value": 47749.0,
            "min": 42513.0,
            "max": 60008.0,
            "count": 40
        },
        "HunterController.Step.mean": {
            "value": 1999866.0,
            "min": 49456.0,
            "max": 1999866.0,
            "count": 40
        },
        "HunterController.Step.sum": {
            "value": 1999866.0,
            "min": 49456.0,
            "max": 1999866.0,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.6322939991950989,
            "min": -18.469682693481445,
            "max": 0.6322939991950989,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicValueEstimate.sum": {
            "value": 109.3868637084961,
            "min": -1635.9810791015625,
            "max": 109.3868637084961,
            "count": 40
        },
        "HunterController.Environment.CumulativeReward.mean": {
            "value": 5.257514595296342,
            "min": -119.89999953560208,
            "max": 5.677167779448404,
            "count": 40
        },
        "HunterController.Environment.CumulativeReward.sum": {
            "value": 909.5500249862671,
            "min": -11030.79995727539,
            "max": 982.150025844574,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicReward.mean": {
            "value": 5.257514595296342,
            "min": -119.89999953560208,
            "max": 5.677167779448404,
            "count": 40
        },
        "HunterController.Policy.ExtrinsicReward.sum": {
            "value": 909.5500249862671,
            "min": -11030.79995727539,
            "max": 982.150025844574,
            "count": 40
        },
        "HunterController.Losses.PolicyLoss.mean": {
            "value": 0.011071804579514719,
            "min": 0.009859309023231616,
            "max": 0.013600063604053502,
            "count": 40
        },
        "HunterController.Losses.PolicyLoss.sum": {
            "value": 0.011071804579514719,
            "min": 0.009859309023231616,
            "max": 0.026469221664592625,
            "count": 40
        },
        "HunterController.Losses.ValueLoss.mean": {
            "value": 63.31809818267822,
            "min": 6.490178627967834,
            "max": 72.04879318237305,
            "count": 40
        },
        "HunterController.Losses.ValueLoss.sum": {
            "value": 63.31809818267822,
            "min": 6.490178627967834,
            "max": 127.76789569854736,
            "count": 40
        },
        "HunterController.Policy.LearningRate.mean": {
            "value": 6.329993671000032e-07,
            "min": 6.329993671000032e-07,
            "max": 9.794715205285005e-05,
            "count": 40
        },
        "HunterController.Policy.LearningRate.sum": {
            "value": 6.329993671000032e-07,
            "min": 6.329993671000032e-07,
            "max": 0.00017287382712619998,
            "count": 40
        },
        "HunterController.Policy.Epsilon.mean": {
            "value": 0.10063290000000003,
            "min": 0.10063290000000003,
            "max": 0.19794715000000007,
            "count": 40
        },
        "HunterController.Policy.Epsilon.sum": {
            "value": 0.10063290000000003,
            "min": 0.10063290000000003,
            "max": 0.3728737999999999,
            "count": 40
        },
        "HunterController.Policy.Beta.mean": {
            "value": 4.158171000000015e-05,
            "min": 4.158171000000015e-05,
            "max": 0.004897562785,
            "count": 40
        },
        "HunterController.Policy.Beta.sum": {
            "value": 4.158171000000015e-05,
            "min": 4.158171000000015e-05,
            "max": 0.008646402619999997,
            "count": 40
        },
        "HunterController.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        },
        "HunterController.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 40
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1713529566",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Lukas\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn C:\\MajorProject\\MP_ML_agents\\Assets\\TrainConfigMAgents.yaml --run-id=PreyVsHunter_54",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.0+cpu",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1713532954"
    },
    "total": 3388.2532715000016,
    "count": 1,
    "self": 0.007034499998553656,
    "children": {
        "run_training.setup": {
            "total": 0.05763150000348105,
            "count": 1,
            "self": 0.05763150000348105
        },
        "TrainerController.start_learning": {
            "total": 3388.1886054999995,
            "count": 1,
            "self": 0.7369519994608709,
            "children": {
                "TrainerController._reset_env": {
                    "total": 3.2874730000003183,
                    "count": 1,
                    "self": 3.2874730000003183
                },
                "TrainerController.advance": {
                    "total": 3384.0795446005395,
                    "count": 42854,
                    "self": 0.3326368005509721,
                    "children": {
                        "env_step": {
                            "total": 3383.7469077999885,
                            "count": 42854,
                            "self": 2599.8356136006078,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 783.5360174005291,
                                    "count": 42854,
                                    "self": 4.796249300707132,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 778.739768099822,
                                            "count": 78904,
                                            "self": 778.739768099822
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.37527679885170073,
                                    "count": 42854,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3384.5937323997387,
                                            "count": 42854,
                                            "is_parallel": true,
                                            "self": 1405.203841699713,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0016793000031611882,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00016340000001946464,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0015159000031417236,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0015159000031417236
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1979.3882114000226,
                                                    "count": 42854,
                                                    "is_parallel": true,
                                                    "self": 31.73111530028109,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 35.83637940023618,
                                                            "count": 42854,
                                                            "is_parallel": true,
                                                            "self": 35.83637940023618
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1826.662550700239,
                                                            "count": 42854,
                                                            "is_parallel": true,
                                                            "self": 1826.662550700239
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 85.1581659992662,
                                                            "count": 85708,
                                                            "is_parallel": true,
                                                            "self": 8.125234197941609,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 77.0329318013246,
                                                                    "count": 342832,
                                                                    "is_parallel": true,
                                                                    "self": 77.0329318013246
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.550000110408291e-05,
                    "count": 1,
                    "self": 3.550000110408291e-05,
                    "children": {
                        "thread_root": {
                            "total": 0.0,
                            "count": 0,
                            "is_parallel": true,
                            "self": 0.0,
                            "children": {
                                "trainer_advance": {
                                    "total": 6767.654044300543,
                                    "count": 247232,
                                    "is_parallel": true,
                                    "self": 7.12326970031063,
                                    "children": {
                                        "process_trajectory": {
                                            "total": 4433.045670700223,
                                            "count": 247232,
                                            "is_parallel": true,
                                            "self": 4432.578151200225,
                                            "children": {
                                                "RLTrainer._checkpoint": {
                                                    "total": 0.46751949999816134,
                                                    "count": 8,
                                                    "is_parallel": true,
                                                    "self": 0.46751949999816134
                                                }
                                            }
                                        },
                                        "_update_policy": {
                                            "total": 2327.4851039000096,
                                            "count": 142,
                                            "is_parallel": true,
                                            "self": 990.4377589001051,
                                            "children": {
                                                "TorchPPOOptimizer.update": {
                                                    "total": 1337.0473449999045,
                                                    "count": 9545,
                                                    "is_parallel": true,
                                                    "self": 1337.0473449999045
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.08460039999772562,
                    "count": 1,
                    "self": 0.00980629999685334,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07479410000087228,
                            "count": 2,
                            "self": 0.07479410000087228
                        }
                    }
                }
            }
        }
    }
}